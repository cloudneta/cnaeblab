---
layout: post
title: 2장 실습 AWS Load Balancer Controller 부하분산 환경 구성하기
subtitle: AWS Load Balancer Controller를 배포하고 구성을 확인합니다.
tags: [eks, 2장]
published: true
---
|목차|
|-----------|
|[1. 기본 네트워크 환경 확인](#1-기본-네트워크-환경-확인)|
|[&nbsp;&nbsp;&nbsp;&nbsp;1.1. 네트워크 기본 정보 확인](#11-네트워크-기본-정보-확인)|
|[&nbsp;&nbsp;&nbsp;&nbsp;1.2. 워커 노드의 네트워크 정보 확인](#12-워커-노드의-네트워크-정보-확인)|
|[&nbsp;&nbsp;&nbsp;&nbsp;1.3. 테스트용 파드 생성 및 확인](#13-테스트용-파드-생성-및-확인)|
|[2. 파드 통신 확인](#2-파드-통신-확인)|
|[&nbsp;&nbsp;&nbsp;&nbsp;2.1. 노드 간 파드 통신](#21-노드-간-파드-통신)|
|[&nbsp;&nbsp;&nbsp;&nbsp;2.2. 파드에서 외부 인터넷 통신 확인](#22-파드에서-외부-인터넷-통신-확인)|
|[&nbsp;&nbsp;&nbsp;&nbsp;2.3. 테스트용 파드 삭제](#23-테스트용-파드-삭제)|
|[3. 최대 파드 생성 확인](#3-최대-파드-생성-확인)|
|[&nbsp;&nbsp;&nbsp;&nbsp;3.1. kube-ops-view 설치](#31-kube-ops-view-설치)|
|[&nbsp;&nbsp;&nbsp;&nbsp;3.2. 최대 파드 생성 및 확인](#32-최대-파드-생성-및-확인)|

<br/>


## 1. AWS Load Balancer Controller 배포

<br/>

이번 실습은 <span style='color:black; background-color:#FFDB58'>**Amazon EKS 원클릭 배포**</span> 환경에서 진행합니다.  
인프라 배포를 진행하지 않은 경우 [링크](https://cloudneta.github.io/cnaeblab/2023-06-01-CH2-1/){:target="_blank"}를 통해 배포 후 복귀 바랍니다.  
그리고 새롭게 인프라를 배포하면 아래 기본 설정 명령을 입력 후 진행 바랍니다.

<details>
<summary><span style='color:orange'>기본 설정 명령어</span></summary>
<div markdown="1">

<br/>

<span style='color:white; background-color:#404040'> **Default 네임 스페이스 변경** </span>  
{% highlight javascript linenos %}
kubectl ns default
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **워커 노드의 IP 변수 선언** </span>  
{% highlight javascript linenos %}
N1=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2a -o jsonpath={.items[0].status.addresses[0].address})

N2=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2b -o jsonpath={.items[0].status.addresses[0].address})

N3=$(kubectl get node --label-columns=topology.kubernetes.io/zone --selector=topology.kubernetes.io/zone=ap-northeast-2c -o jsonpath={.items[0].status.addresses[0].address})

echo "export N1=$N1" >> /etc/profile

echo "export N2=$N2" >> /etc/profile

echo "export N3=$N3" >> /etc/profile
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **kube-ops-view 설치** </span>  
{% highlight javascript linenos %}
// kube-ops-view 설치
helm repo add geek-cookbook https://geek-cookbook.github.io/charts/

helm install kube-ops-view geek-cookbook/kube-ops-view --version 1.2.2 --set env.TZ="Asia/Seoul" --namespace kube-system

kubectl patch svc -n kube-system kube-ops-view -p '{"spec":{"type":"LoadBalancer"}}'

// kube-ops-view 접속 URL 확인 (1.5 배율)
kubectl get svc -n kube-system kube-ops-view -o jsonpath={.status.loadBalancer.ingress[0].hostname} | awk '{ print "KUBE-OPS-VIEW URL = http://"$1":8080/#scale=1.5"}'
{% endhighlight %}

<br/>



</div>
</details>

<br/>

### 1.1. IRSA 구성

AWS Load Balancer Controller 배포에 앞서 권한을 위임하기 위한 인증 절차로 IRSA 구성을 선행합니다.

<br/>

<span style='color:white; background-color:#404040'> **OIDC 정보 확인** </span>  
{% highlight javascript linenos %}
aws eks describe-cluster --name $CLUSTER_NAME \
  --query "cluster.identity.oidc.issuer" \
  --output text
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **AWSLoadBalancerControllerIAMPolicy 생성** </span>  
{% highlight javascript linenos %}
// IAM Policy json 파일 다운로드
curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.4.7/docs/install/iam_policy.json

// AWSLoadBalancerControllerIAMPolicy 생성
aws iam create-policy --policy-name AWSLoadBalancerControllerIAMPolicy --policy-document file://iam_policy.json
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **IRSA 생성** </span>  
{% highlight javascript linenos %}
// IRSA 생성
eksctl create iamserviceaccount \
  --cluster=$CLUSTER_NAME \
  --namespace=kube-system \
  --name=aws-load-balancer-controller \
  --attach-policy-arn=arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy \
  --override-existing-serviceaccounts \
  --approve

// IRSA 정보 확인
eksctl get iamserviceaccount --cluster $CLUSTER_NAME

// Kubernetes 서비스 어카운트 확인
kubectl get serviceaccounts -n kube-system aws-load-balancer-controller -o yaml | yh
{% endhighlight %}

<br/><br/>


### 1.2. AWS Load Balancer Controller 설치

<br/>

<span style='color:white; background-color:#404040'> **AWS Load Balancer Controller 설치** </span>  
{% highlight javascript linenos %}
// Helm Chart Repogitory 추가 및 업데이트
helm repo add eks https://aws.github.io/eks-charts
helm repo update

// Helm Chart - AWS Load Balancer Controller 설치
helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system \
  --set clusterName=$CLUSTER_NAME \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **AWS Load Balancer Controller 설치 확인** </span>  
{% highlight javascript linenos %}
// Kubernetes CRD 확인
kubectl get crd

// AWS Load Balancer Controller 확인
kubectl get deployment -n kube-system aws-load-balancer-controller

kubectl describe deploy -n kube-system aws-load-balancer-controller

// AWS Load Balancer Controller Role 확인
kubectl describe clusterroles.rbac.authorization.k8s.io aws-load-balancer-controller-role
{% endhighlight %}

<br/>

---

<br/>

## 2. Service(NLB) 배포 및 확인

<br/>

AWS Load Balancer Controller를 배포한 상태에서 Service의 LoadBalancer인 NLB를 구성하고 통신을 확인합니다.

<br/>

### 2.1. Service NLB 배포 및 확인

<br/>

<span style='color:white; background-color:#404040'> **파드 IP 변수 지정** </span>  
{% highlight javascript linenos %}
// 생성된 각 파드의 IP 주소를 변수로 지정
PODIP1=$(kubectl get pods -o custom-columns=:.metadata.name,PodIP:status.podIP | grep 192.168.1. | cut -c 33-)

PODIP2=$(kubectl get pods -o custom-columns=:.metadata.name,PodIP:status.podIP | grep 192.168.2. | cut -c 33-)

PODIP3=$(kubectl get pods -o custom-columns=:.metadata.name,PodIP:status.podIP | grep 192.168.3. | cut -c 33-)

// 파드 IP 확인 및 변수 호출
kubectl get pods -o custom-columns=PodNAME:.metadata.name,PodIP:status.podIP

echo $PODIP1, $PODIP2, $PODIP3
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **신규 터미널 3개에 tcpdump 수행** </span>  
{% highlight javascript linenos %}
// 워커 노드1의 모든 인터페이스에 tcpdump
ssh ec2-user@$N1

sudo tcpdump -i any -nn icmp

// 워커 노드2의 모든 인터페이스에 tcpdump
ssh ec2-user@$N2

sudo tcpdump -i any -nn icmp

// 워커 노드3의 모든 인터페이스에 tcpdump
ssh ec2-user@$N3

sudo tcpdump -i any -nn icmp
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **파드 간 ping 테스트** </span>  
{% highlight javascript linenos %}
// 파드1에서 파드2로 ping
kubectl exec -it $PODNAME1 -- ping -c 2 $PODIP2

// 파드1에서 파드3으로 ping
kubectl exec -it $PODNAME1 -- ping -c 2 $PODIP3

// 파드2에서 파드3으로 ping
kubectl exec -it $PODNAME2 -- ping -c 2 $PODIP3
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **파드와 노드의 라우팅 확인** </span>  
{% highlight javascript linenos %}
// 파드 1에서 라우팅 확인
kubectl exec -it $PODNAME1 -- ip -br addr

kubectl exec -it $PODNAME1 -- ip route show table main

// 워커 노드에서 라우팅 확인
ssh ec2-user@$N1 sudo ip route show table main

ssh ec2-user@$N3 sudo ip route show table main
{% endhighlight %}

<br/>


### 2.2. 파드에서 외부 인터넷 통신 확인


<br/>

<span style='color:white; background-color:#404040'> **신규 터미널에 tcpdump 수행** </span>

{% highlight javascript linenos %}
// 워커 노드1의 모든 인터페이스에 tcpdump
ssh ec2-user@$N1

sudo tcpdump -i any -nn icmp
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **파드 1에서 외부 인터넷 통신** </span>

{% highlight javascript linenos %}
// google.com으로 ping
kubectl exec -it $PODNAME1 -- ping -c 1 www.google.com
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **파드와 워커 노드의 공인 IP 확인** </span>

{% highlight javascript linenos %}
// 파드 1의 공인 IP 주소 확인
kubectl exec -it $PODNAME1 -- curl -s ipinfo.io/ip ; echo

// 워커 노드 1의 공인 IP 주소 확인
ssh ec2-user@$N1 curl -s ipinfo.io/ip ; echo
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **워커 노드 1의 NAT 테이블 확인** </span>

{% highlight javascript linenos %}
// 워커 노드 1에서 NAT 테이블 확인
ssh ec2-user@$N1 sudo iptables -L -n -v -t nat

// 워커 노드 1에서 NAT Rule List 확인
ssh ec2-user@$N1 sudo iptables -t nat -S

ssh ec2-user@$N1 sudo iptables -t nat -S | grep 'A AWS-SNAT-CHAIN'
{% endhighlight %}

<br/>

### 2.3. 테스트용 파드 삭제


<br/>

<span style='color:white; background-color:#404040'> **테스트용 파드 삭제** </span>

{% highlight javascript linenos %}
kubectl delete deploy netshoot-pod
{% endhighlight %}

<br/>

---

<br/>

## 3. 최대 파드 생성 확인

<br/>

앞선 실습 환경에서 다수의 파드를 생성하여 최대 파드 생성 개수를 확인합니다.

<br/>

### 3.1. kube-ops-view 설치

실습의 이해를 돕기 위해 [kube-ops-view](https://codeberg.org/hjacobs/kube-ops-view){:target="_blank"}라는 가시성 도구를 설치합니다.  
해당 도구를 통해 워커 노드에 구성된 파드 정보를 쉽게 확인할 수 있습니다.

<br/>

<span style='color:white; background-color:#404040'> **kube-ops-view 설치** </span>
{% highlight javascript linenos %}
// kube-ops-view 설치
helm repo add geek-cookbook https://geek-cookbook.github.io/charts/

helm install kube-ops-view geek-cookbook/kube-ops-view --version 1.2.2 --set env.TZ="Asia/Seoul" --namespace kube-system

kubectl patch svc -n kube-system kube-ops-view -p '{"spec":{"type":"LoadBalancer"}}'

// kube-ops-view 접속 URL 확인 (1.5 배율)
kubectl get svc -n kube-system kube-ops-view -o jsonpath={.status.loadBalancer.ingress[0].hostname} | awk '{ print "KUBE-OPS-VIEW URL = http://"$1":8080/#scale=1.5"}'
{% endhighlight %}

{: .box-note}
**Note:** 위 출력되는 kube-ops-view URL로 인터넷 브라우저에서 접속합니다.

<br/>

### 3.2. 최대 파드 생성 및 확인

<br/>

<span style='color:white; background-color:#404040'> **워커 노드의 인스턴스 정보 확인** </span>
{% highlight javascript linenos %}
// t3 타입의 인스턴스 정보 (최대 ENI 수량, 최대 IP 수량)
aws ec2 describe-instance-types --filters Name=instance-type,Values=t3.* \
 --query "InstanceTypes[].{Type: InstanceType, MaxENI: NetworkInfo.MaximumNetworkInterfaces, IPv4addr: NetworkInfo.Ipv4AddressesPerInterface}" \
 --output table

// m5 타입의 인스턴스 정보 (최대 ENI 수량, 최대 IP 수량)
aws ec2 describe-instance-types --filters Name=instance-type,Values=m5.* \
 --query "InstanceTypes[].{Type: InstanceType, MaxENI: NetworkInfo.MaximumNetworkInterfaces, IPv4addr: NetworkInfo.Ipv4AddressesPerInterface}" \
 --output table

// 워커 노드의 상세 정보 확인 (Allocatable - pods)
kubectl describe node | grep Allocatable: -A7
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **최대 파드 생성 관련 모니터링(신규 터미널 2개)** </span>
{% highlight javascript linenos %}
// 신규 터미널 1 - 워커 노드 1에서 인터페이스 정보 모니터링
ssh ec2-user@$N1

while true; do ip -br -c addr show && echo "--------------" ; date "+%Y-%m-%d %H:%M:%S" ; sleep 1; done

// 신규 터미널 2 - 작업용 인스턴스에서 파드 정보 모니터링
watch -d 'kubectl get pods -o wide'
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **최대 파드 생성 작업** </span>
{% highlight javascript linenos %}
// 디플로이먼트 생성 (최초 2대)
curl -s -O https://raw.githubusercontent.com/cloudneta/cnaeblab/master/_data/nginx-dp.yaml

kubectl apply -f nginx-dp.yaml

// 파드 수량 8대로 변경 (replicas)
kubectl scale deployment nginx-deployment --replicas=8

// 파드 수량 30대로 변경 (replicas)
kubectl scale deployment nginx-deployment --replicas=30

// 파드 수량 3대로 변경 (replicas)
kubectl scale deployment nginx-deployment --replicas=3

// 파드 수량 50대로 변경 (replicas)
kubectl scale deployment nginx-deployment --replicas=50
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **파드 초과 생성으로 대기 중인 파드 확인** </span>
{% highlight javascript linenos %}
// 대기 중인 파드 확인
kubectl get pods | grep Pending

// 대기 중인 파드 지정하여 정보 확인
kubectl describe pod [대기 파드 이름]
{% endhighlight %}

<br/>

<span style='color:white; background-color:#404040'> **디플로이먼트 삭제** </span>
{% highlight javascript linenos %}
// 디플로이먼트 삭제
kubectl delete deploy nginx-deployment
{% endhighlight %}

<br/>

{: .box-warning}
**Warning:** 다음 섹션의 실습을 이어서 진행할 것으로 Amazon EKS 원클릭 배포를 유지합니다. 혹시나 다음 섹션을 진행하지 않을 경우 Amazon EKS 원클릭 배포를 삭제해 주길 바랍니다.

---

<br/>

여기까지 2장의 Amazon VPC CNI 실습을 마칩니다.  
수고하셨습니다 :)

<br/><br/>
